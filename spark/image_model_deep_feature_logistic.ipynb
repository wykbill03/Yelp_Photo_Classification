{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "directly build logistic regression on image level with deep learning features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "# from pyspark.mllib.feature import HashingTF, IDF\n",
    "# from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "from StringIO import StringIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import csv\n",
    "import os, tempfile\n",
    "import boto\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS S3 credentials:\n",
    "\n",
    "AWS_KEY = \"\"\n",
    "AWS_SECRET = \"\"\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", AWS_KEY)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", AWS_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training image deep learning features\n",
    "features_train = sc.textFile('s3n://amlyelp/fc7features/train_image_fc7features/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'11598', array([ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          2.57181787,  0.        ])),\n",
       " (u'295391',\n",
       "  array([ 0.       ,  0.       ,  0.       , ...,  1.5179913,  0.       ,  0.       ]))]"
      ]
     },
     "execution_count": 24,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "pid_features_train=features_train.map(lambda x: tuple(x.split('|'))).mapValues(lambda x: np.array(x.split(','),dtype=float))\n",
    "pid_features_train.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'204149',\n",
       "  {'labels': array([0, 0, 0, 1, 0, 0, 0, 0, 1]), 'restaurant': u'3034'})]"
      ]
     },
     "execution_count": 25,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# map training image to label, restaurant\n",
    "train_label = sc.textFile('s3n://amlyelp/pic_label_trainall.csv')\n",
    "first_line = train_label.take(1)[0]\n",
    "train_label = train_label.filter(lambda x: x!= first_line).map(lambda x: x.split(','))\\\n",
    "                            .map(lambda x: (x[0],{'restaurant':x[1],'labels':np.array(x[2:11],dtype=int)}))\n",
    "train_label.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'378466',\n",
       "  ({'labels': array([0, 0, 0, 1, 0, 0, 0, 0, 0]), 'restaurant': u'227'},\n",
       "   array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))),\n",
       " (u'35540',\n",
       "  ({'labels': array([0, 1, 1, 0, 1, 1, 1, 1, 0]), 'restaurant': u'2611'},\n",
       "   array([ 0.        ,  0.        ,  0.        , ...,  5.03832006,\n",
       "           0.        ,  0.        ])))]"
      ]
     },
     "execution_count": 27,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# join training image, label and features\n",
    "id_label_feature_train = train_label.leftOuterJoin(pid_features_train)\n",
    "id_label_feature_train.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'306310', array([ 0.,  0.,  0., ...,  0.,  0.,  0.])),\n",
       " (u'414079',\n",
       "  array([ 1.7991451,  0.       ,  0.       , ...,  0.       ,  0.       ,  0.       ]))]"
      ]
     },
     "execution_count": 28,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# read testing image features\n",
    "features_test = sc.textFile('s3n://amlyelp/fc7features/test_image_fc7features/')\n",
    "pid_features_test=features_test.map(lambda x: tuple(x.split('|'))).mapValues(lambda x: np.array(x.split(','),dtype=float))\n",
    "pid_features_test.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build logistic regression for 1 label\n",
    "i=0\n",
    "train = id_label_feature_train.map(lambda x: LabeledPoint(x[1][0]['labels'][i], x[1][1])).repartition(120).cache()\n",
    "# train.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LogisticRegressionWithLBFGS.train(train, intercept=True, validateData=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'306310', 0.1442900951215041),\n",
       " (u'414079', 0.7516735861272454),\n",
       " (u'235737', 0.04615771435067375),\n",
       " (u'6011', 0.0200634977117878),\n",
       " (u'349578', 0.42398592348472686),\n",
       " (u'42644', 0.041748559818473606),\n",
       " (u'358960', 0.11008557094520433)]"
      ]
     },
     "execution_count": 33,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "lrm.clearThreshold()\n",
    "prediction = pid_features_test.mapValues(lambda x: lrm.predict(x))\n",
    "prediction.take(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.map(lambda x: ','.join(np.array(x, dtype=np.str)))\\\n",
    ".saveAsTextFile('s3n://amlyelp/fc7features_pred/prob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = prediction.map(lambda x: ','.join(np.array(x, dtype=np.str))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpf = '\\n'.join(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237152"
      ]
     },
     "execution_count": 41,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto.s3.connection import S3Connection\n",
    "from boto.s3.key import Key\n",
    "\n",
    "AWS_KEY = \"\"\n",
    "AWS_SECRET = \"\"\n",
    "\n",
    "conn = S3Connection(AWS_KEY, AWS_SECRET, host='s3.amazonaws.com')\n",
    "pb = conn.get_bucket('amlyelp')\n",
    "\n",
    "k = Key(pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5211857"
      ]
     },
     "execution_count": 43,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# s3_file = \"image_cluster_%s.csv\" % str(datetime.datetime.now()).replace(' ', '_').replace('.','_')\n",
    "# s3_path = \"subset/image_cluster_result\"\n",
    "# file_name_to_use_in_s3 = \"%s/%s\"%(s3_path, s3_file)\n",
    "# file_name_to_use_in_s3 = 'fc7features_pred/prob_trial.csv'\n",
    "# k.name = file_name_to_use_in_s3\n",
    "# k.set_contents_from_string(tmpf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and predict for each label and write to S3\n",
    "for i in range(9):\n",
    "    train = id_label_feature_train.map(lambda x: LabeledPoint(x[1][0]['labels'][i], x[1][1])).repartition(120).cache()\n",
    "\n",
    "    lrm = LogisticRegressionWithLBFGS.train(train, intercept=True, validateData=False)\n",
    "\n",
    "    lrm.clearThreshold()\n",
    "    prediction = pid_features_test.mapValues(lambda x: lrm.predict(x))\n",
    "    prediction_list = prediction.map(lambda x: ','.join(np.array(x, dtype=np.str))).collect()\n",
    "    tmpf = '\\n'.join(prediction_list)\n",
    "    del prediction_list\n",
    "    \n",
    "    file_name_to_use_in_s3 = 'fc7features_pred/prob_%d.csv' % i\n",
    "    k.name = file_name_to_use_in_s3\n",
    "    k.set_contents_from_string(tmpf)\n",
    "    del tmpf\n",
    "    del train\n",
    "    del lrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}