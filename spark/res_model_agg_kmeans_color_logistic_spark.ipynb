{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build logistic regression model based on cluster percentages under each restaurant  \n",
    "and predict restaurant labels\n",
    "\n",
    "Clusters are predicted by k-means on image color features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, tempfile\n",
    "import boto\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AWS S3 credentials:\n",
    "\n",
    "AWS_KEY = \"\"\n",
    "AWS_SECRET = \"\"\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", AWS_KEY)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", AWS_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from boto.s3.connection import S3Connection\n",
    "from boto.s3.key import Key\n",
    "\n",
    "AWS_KEY = \"\"\n",
    "AWS_SECRET = \"\"\n",
    "\n",
    "conn = S3Connection(AWS_KEY, AWS_SECRET, host='s3.amazonaws.com')\n",
    "pb = conn.get_bucket('amlyelp')\n",
    "\n",
    "k = Key(pb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data and saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read saved k-means model\n",
    "path = 's3n://amlyelp/subset/model/kmeans/color_feature_3_2016-03-05_23_09_58.393414/'\n",
    "clusters = KMeansModel.load(sc, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'28034', u'14'), (u'28863', u'31')]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training picture and clusters\n",
    "cluster_path = 's3n://amlyelp/subset/image_cluster_result/image_cluster_color_feature_3_2016-03-05_23_12_29_238662/'\n",
    "# cluster_path = 's3n://amlyelp/subset/image_cluster_result/image_cluster_deep_feature_2016-03-01_19_21_17_105238/'\n",
    "\n",
    "photo_cluster_map = sc.textFile(cluster_path)\n",
    "# parse training picture clusters\n",
    "photo_cluster_map = photo_cluster_map.map(lambda x: x.replace(\"(u\",'').replace(\"'\",'').replace(')','').split(','))\n",
    "photo_cluster_map = photo_cluster_map.map(lambda x: (x[0].strip(), x[1].strip()))\n",
    "photo_cluster_map.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61718"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_cluster_map.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'80', array([ 0.,  0.,  0., ...,  0.,  0.,  0.]))]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test set deep feature\n",
    "test_feature_path = 's3n://amlyelp/subset/F3_testfinal.csv'\n",
    "test_feature = sc.textFile(test_feature_path)\n",
    "\n",
    "test_feature_parsed = test_feature.map(lambda x: x.split(','))\\\n",
    "                  .map(lambda x: (x[0], np.array(x[1].split(' ')).astype(np.float)))\n",
    "test_feature_parsed.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'5', u'3305', u'0', u'0', u'0', u'1', u'0', u'0', u'1', u'0', u'0']]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training photo_id, res_id, labels\n",
    "label_path = 's3n://amlyelp/subset/pic_label_subbybus_train.csv'\n",
    "photo_res_label = sc.textFile(label_path)\n",
    "first_line = photo_res_label.take(1)[0]\n",
    "photo_res_label = photo_res_label.filter(lambda x: x!= first_line).map(lambda x: x.split(','))\n",
    "photo_res_label.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'80', u'1114', u'0', u'1', u'1', u'0', u'1', u'1', u'1', u'1', u'0']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test photo_id, res_id, labels\n",
    "test_label_path = 's3n://amlyelp/subset/pic_label_subbybus_test.csv'\n",
    "test_photo_res_label = sc.textFile(test_label_path)\n",
    "test_first_line = test_photo_res_label.take(1)[0]\n",
    "test_photo_res_label = test_photo_res_label.filter(lambda x: x!= test_first_line).map(lambda x: x.split(','))\n",
    "test_photo_res_label.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'216', [u'1', u'0', u'0', u'1', u'0', u'1', u'0', u'0', u'1']),\n",
       " (u'1788', [u'1', u'0', u'0', u'0', u'0', u'1', u'0', u'0', u'1'])]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract training res_id, labels\n",
    "res_label = photo_res_label.map(lambda x: (x[1], x[2:])).combineByKey(lambda x: x,\n",
    "                                           lambda u, v: u,\n",
    "                                           lambda u1,u2: u1)\n",
    "res_label.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'393', u'27'), (u'3241', u'19')]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass picture cluster to restaurant\n",
    "res_cluster = photo_res_label.map(lambda x: (x[0],x[1])).leftOuterJoin(photo_cluster_map).map(lambda x: x[1])\n",
    "res_cluster.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'692',\n",
       "  {1: 0.06060606060606061,\n",
       "   4: 0.030303030303030304,\n",
       "   5: 0.10606060606060606,\n",
       "   6: 0.06060606060606061,\n",
       "   8: 0.030303030303030304,\n",
       "   12: 0.030303030303030304,\n",
       "   16: 0.015151515151515152,\n",
       "   19: 0.13636363636363635,\n",
       "   21: 0.030303030303030304,\n",
       "   22: 0.030303030303030304,\n",
       "   23: 0.015151515151515152,\n",
       "   24: 0.015151515151515152,\n",
       "   26: 0.030303030303030304,\n",
       "   27: 0.015151515151515152,\n",
       "   29: 0.015151515151515152,\n",
       "   30: 0.015151515151515152,\n",
       "   31: 0.07575757575757576,\n",
       "   33: 0.06060606060606061,\n",
       "   43: 0.045454545454545456,\n",
       "   48: 0.18181818181818182})]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine clusters by restaurant and \n",
    "# calculate ratio of each picture cluster under each restaurant as features\n",
    "agg_res_cluster = res_cluster.combineByKey(lambda x: [x],\n",
    "                                           lambda u, v: u+[v],\n",
    "                                           lambda u1,u2: u1+u2)\n",
    "agg_res_cluster = agg_res_cluster.mapValues(lambda x: Counter(x))\\\n",
    "                                .map(lambda x: (x[0], {int(k):float(v)/np.sum(x[1].values()) for k,v in x[1].iteritems()}))\n",
    "agg_res_cluster.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'120',\n",
       "  {1: 0.14545454545454545,\n",
       "   4: 0.03636363636363636,\n",
       "   5: 0.07272727272727272,\n",
       "   8: 0.01818181818181818,\n",
       "   9: 0.03636363636363636,\n",
       "   12: 0.14545454545454545,\n",
       "   14: 0.05454545454545454,\n",
       "   21: 0.03636363636363636,\n",
       "   22: 0.03636363636363636,\n",
       "   24: 0.05454545454545454,\n",
       "   26: 0.05454545454545454,\n",
       "   27: 0.07272727272727272,\n",
       "   29: 0.01818181818181818,\n",
       "   30: 0.03636363636363636,\n",
       "   33: 0.03636363636363636,\n",
       "   37: 0.05454545454545454,\n",
       "   39: 0.01818181818181818,\n",
       "   43: 0.07272727272727272},\n",
       "  [u'0', u'1', u'1', u'0', u'0', u'1', u'1', u'0', u'1'])]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge cluster ratio feature and labels\n",
    "res_cluster_label = agg_res_cluster.leftOuterJoin(res_label).map(lambda x: (x[0],x[1][0],x[1][1]))\n",
    "res_cluster_label.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cluster_label.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'80', 8), (u'95', 6)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test picture clusters\n",
    "test_image_cluster = test_feature_parsed.map(lambda x: (x[0],clusters.predict(x[1])))\n",
    "test_image_cluster.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'881', [u'1', u'1', u'0', u'1', u'0', u'1', u'0', u'0', u'1'])]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract test res_id, labels\n",
    "test_res_label = test_photo_res_label.map(lambda x: (x[1], x[2:])).combineByKey(lambda x: x,\n",
    "                                           lambda u, v: u,\n",
    "                                           lambda u1,u2: u1)\n",
    "test_res_label.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1160', 43), (u'485', 33), (u'1114', 1)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass test picture cluster to restaurant\n",
    "test_res_cluster = test_photo_res_label.map(lambda x: (x[0],x[1])).leftOuterJoin(test_image_cluster).map(lambda x: x[1])\n",
    "test_res_cluster.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine clusters by restaurant and \n",
    "# calculate ratio of each picture cluster under each restaurant as features\n",
    "test_agg_res_cluster = test_res_cluster.combineByKey(lambda x: [x],\n",
    "                                           lambda u, v: u+[v],\n",
    "                                           lambda u1,u2: u1+u2)\\\n",
    "                                .mapValues(lambda x: Counter(x))\\\n",
    "                                .map(lambda x: (x[0], {int(k):float(v)/np.sum(x[1].values()) for k,v in x[1].iteritems()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge test cluster ratio feature and labels\n",
    "test_res_cluster_label = test_agg_res_cluster.leftOuterJoin(test_res_label).map(lambda x: (x[0],x[1][0],x[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.717171717172 0.588235294118\n",
      "1 0.79797979798 0.818181818182\n",
      "2 0.79797979798 0.811320754717\n",
      "3 0.59595959596 0.574468085106\n",
      "4 0.787878787879 0.655737704918\n",
      "5 0.79797979798 0.84375\n",
      "6 0.777777777778 0.845070422535\n",
      "7 0.79797979798 0.705882352941\n",
      "8 0.757575757576 0.796610169492\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.DataFrame(test_res_cluster_label.map(lambda x: x[0]).collect(),columns=['restaurant_id'])\n",
    "for i in range(9):\n",
    "    train = res_cluster_label.map(lambda x: LabeledPoint(int(x[2][i]), SparseVector(50, x[1]))).cache()\n",
    "    test = test_res_cluster_label.map(lambda x: LabeledPoint(int(x[2][i]), SparseVector(50, x[1]))).cache()\n",
    "    lrm = LogisticRegressionWithLBFGS.train(train, intercept=True, validateData=False)\n",
    "\n",
    "    labelsAndPreds = zip(*test.map(lambda p: (lrm.predict(p.features), p.label)).collect())\n",
    "\n",
    "    current_f1 = f1_score(y_true=labelsAndPreds[1], y_pred=labelsAndPreds[0])\n",
    "    current_accuracy = accuracy_score(y_true=labelsAndPreds[1], y_pred=labelsAndPreds[0])\n",
    "    prediction[('label_%d' % i)]=pd.Series(labelsAndPreds[0])\n",
    "    \n",
    "#     # if predict proba instead of labels\n",
    "#     lrm.clearThreshold()\n",
    "#     labelsAndProbs = zip(*test.map(lambda p: (lrm.predict(p.features), p.label)).collect())\n",
    "#     current_auc = roc_auc_score(y_true=labelsAndProbs[1], y_score=labelsAndProbs[0])\n",
    "    \n",
    "    print i, current_accuracy, current_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score function\n",
    "def mlb_f1(y_true, y_pred):\n",
    "    y_true = set(y_true)\n",
    "    y_pred = set(y_pred)\n",
    "    tp = len(y_true & y_pred)\n",
    "    fp = len(y_pred-y_true)\n",
    "    fn = len(y_true-y_pred)\n",
    "    p = float(tp)/(tp+fp)\n",
    "    r = float(tp)/(tp+fn)\n",
    "    return 2*p*r/(p+r) if tp!=0 else 0.\n",
    "def mean_f1(y_true, y_pred):\n",
    "    score_list = map(lambda x: mlb_f1(x[0],x[1]), zip(y_true, y_pred))\n",
    "    return sum(score_list)/len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252071721768684"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [[i for i in range(len(arr)) if arr[i]!=0] for arr in np.array(prediction.iloc[:,1:])]\n",
    "y_true_array = np.array(test_res_cluster_label.map(lambda x: x[2]).collect()).astype(int)\n",
    "y_true = [[i for i in range(len(arr)) if arr[i]!=0] for arr in y_true_array]\n",
    "mean_f1(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_labels_array = np.array(test_res_cluster_label.map(lambda x: x[2]).collect())\n",
    "test_labels_count = [Counter(arr) for arr in test_labels_array.T]\n",
    "test_labels_freq = [{k:float(v)/np.sum(dict_.values()) for k,v in dict_.iteritems()} for dict_ in test_labels_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'0': 0.6363636363636364, u'1': 0.36363636363636365},\n",
       " {u'0': 0.43434343434343436, u'1': 0.5656565656565656},\n",
       " {u'0': 0.45454545454545453, u'1': 0.5454545454545454},\n",
       " {u'0': 0.5151515151515151, u'1': 0.48484848484848486},\n",
       " {u'0': 0.6868686868686869, u'1': 0.31313131313131315},\n",
       " {u'0': 0.32323232323232326, u'1': 0.6767676767676768},\n",
       " {u'0': 0.25252525252525254, u'1': 0.7474747474747475},\n",
       " {u'0': 0.6161616161616161, u'1': 0.3838383838383838},\n",
       " {u'0': 0.42424242424242425, u'1': 0.5757575757575758}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upload prediction to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s3_file = \"deep_cluster_prediction.csv\"\n",
    "# s3_path = \"subset\"\n",
    "# file_name_to_use_in_s3 = \"%s/%s\"%(s3_path, s3_file)\n",
    "# k.name = file_name_to_use_in_s3\n",
    "# with tempfile.TemporaryFile() as tmpf:\n",
    "#     prediction.to_csv(tmpf, index=False)\n",
    "#     tmpf.seek(0)\n",
    "#     k.set_contents_from_file(tmpf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
