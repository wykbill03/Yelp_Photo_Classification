{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build logistic regression model based on cluster percentages under each restaurant  \n",
    "and predict restaurant labels\n",
    "\n",
    "Clusters are predicted by k-means on image deep learning features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, tempfile\n",
    "import boto\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "from pyspark.mllib.clustering import KMeans, KMeansModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AWS S3 credentials:\n",
    "\n",
    "AWS_KEY = \"\"\n",
    "AWS_SECRET = \"\"\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", AWS_KEY)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", AWS_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read saved k-means model\n",
    "path = 's3n://amlyelp/subset/model/kmeans/deep_feature_2016-03-01_19_20_50.068026/'\n",
    "clusters = KMeansModel.load(sc, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'5', u'3305', u'0', u'0', u'0', u'1', u'0', u'0', u'1', u'0', u'0']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read training photo_id, restaurant_id, labels\n",
    "label_path = 's3n://amlyelp/subset/pic_label_subbybus_train.csv'\n",
    "photo_res_label = sc.textFile(label_path)\n",
    "first_line = photo_res_label.take(1)[0]\n",
    "photo_res_label = photo_res_label.filter(lambda x: x!= first_line).map(lambda x: x.split(','))\n",
    "photo_res_label.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'216', [u'1', u'0', u'0', u'1', u'0', u'1', u'0', u'0', u'1']),\n",
       " (u'1788', [u'1', u'0', u'0', u'0', u'0', u'1', u'0', u'0', u'1'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract training res_id, labels\n",
    "res_label = photo_res_label.map(lambda x: (x[1], x[2:])).combineByKey(lambda x: x,\n",
    "                                           lambda u, v: u,\n",
    "                                           lambda u1,u2: u1)\n",
    "res_label.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read training picture and clusters\n",
    "cluster_path = 's3n://amlyelp/subset/image_cluster_result/image_cluster_deep_feature_2016-03-01_19_21_17_105238/'\n",
    "# cluster_path = 's3n://amlyelp/subset/image_cluster_result/image_cluster_deep_feature_2016-03-01_19_21_17_105238/'\n",
    "\n",
    "photo_cluster_map = sc.textFile(cluster_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'448995', u'32'), (u'414570', u'29')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse training picture clusters\n",
    "photo_cluster_map = photo_cluster_map.map(lambda x: x.replace(\"(u\",'').replace(\"'\",'').replace(')','').split(','))\n",
    "photo_cluster_map = photo_cluster_map.map(lambda x: (x[0].strip(), x[1].strip()))\n",
    "photo_cluster_map.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'227', u'35'), (u'3485', u'10')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass picture cluster to restaurant\n",
    "res_cluster = photo_res_label.map(lambda x: (x[0],x[1])).leftOuterJoin(photo_cluster_map).map(lambda x: x[1])\n",
    "res_cluster.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'3775',\n",
       "  {0: 0.04,\n",
       "   5: 0.16,\n",
       "   8: 0.04,\n",
       "   12: 0.04,\n",
       "   13: 0.04,\n",
       "   14: 0.04,\n",
       "   16: 0.04,\n",
       "   17: 0.04,\n",
       "   19: 0.08,\n",
       "   24: 0.24,\n",
       "   31: 0.04,\n",
       "   34: 0.04,\n",
       "   40: 0.04,\n",
       "   43: 0.04,\n",
       "   46: 0.04,\n",
       "   47: 0.04})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine clusters by restaurant and \n",
    "# calculate ratio of each picture cluster under each restaurant as features\n",
    "agg_res_cluster = res_cluster.combineByKey(lambda x: [x],\n",
    "                                           lambda u, v: u+[v],\n",
    "                                           lambda u1,u2: u1+u2)\n",
    "agg_res_cluster = agg_res_cluster.mapValues(lambda x: Counter(x))\\\n",
    "                                .map(lambda x: (x[0], {int(k):float(v)/np.sum(x[1].values()) for k,v in x[1].iteritems()}))\n",
    "agg_res_cluster.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'590',\n",
       "  {0: 0.07692307692307693,\n",
       "   2: 0.02564102564102564,\n",
       "   4: 0.02564102564102564,\n",
       "   5: 0.07692307692307693,\n",
       "   8: 0.02564102564102564,\n",
       "   9: 0.05128205128205128,\n",
       "   12: 0.02564102564102564,\n",
       "   14: 0.02564102564102564,\n",
       "   18: 0.02564102564102564,\n",
       "   20: 0.05128205128205128,\n",
       "   23: 0.1282051282051282,\n",
       "   25: 0.10256410256410256,\n",
       "   29: 0.02564102564102564,\n",
       "   30: 0.02564102564102564,\n",
       "   31: 0.02564102564102564,\n",
       "   41: 0.07692307692307693,\n",
       "   44: 0.05128205128205128,\n",
       "   45: 0.10256410256410256,\n",
       "   46: 0.02564102564102564,\n",
       "   49: 0.02564102564102564},\n",
       "  [u'1', u'1', u'0', u'0', u'0', u'1', u'1', u'0', u'1'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge cluster ratio feature and labels\n",
    "res_cluster_label = agg_res_cluster.leftOuterJoin(res_label).map(lambda x: (x[0],x[1][0],x[1][1]))\n",
    "res_cluster_label.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_cluster_label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'245805',\n",
       "  array([ 0.      ,  0.35613 ,  0.      , ...,  0.      ,  0.437566,  0.      ]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test set deep learning feature\n",
    "test_feature_path = 's3n://amlyelp/subset/test_subset_deep_feature.csv'\n",
    "test_feature = sc.textFile(test_feature_path)\n",
    "test_first = test_feature.take(1)[0]\n",
    "test_feature = test_feature.filter(lambda x: x!=test_first)\n",
    "\n",
    "test_feature_parsed = test_feature.map(lambda x: x.replace('[','').replace(']','').replace('\"','').split(','))\\\n",
    "                  .map(lambda x: (x[0], np.array(map(float, x[1].split(' ')))))\n",
    "test_feature_parsed.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'245805', 30), (u'363726', 49)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict test picture clusters\n",
    "test_image_cluster = test_feature_parsed.map(lambda x: (x[0],clusters.predict(x[1])))\n",
    "test_image_cluster.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'80', u'1114', u'0', u'1', u'1', u'0', u'1', u'1', u'1', u'1', u'0']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read test photo_id, res_id, labels\n",
    "test_label_path = 's3n://amlyelp/subset/pic_label_subbybus_test.csv'\n",
    "test_photo_res_label = sc.textFile(test_label_path)\n",
    "test_first_line = test_photo_res_label.take(1)[0]\n",
    "test_photo_res_label = test_photo_res_label.filter(lambda x: x!= test_first_line).map(lambda x: x.split(','))\n",
    "test_photo_res_label.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'881', [u'1', u'1', u'0', u'1', u'0', u'1', u'0', u'0', u'1'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract test res_id, labels\n",
    "test_res_label = test_photo_res_label.map(lambda x: (x[1], x[2:])).combineByKey(lambda x: x,\n",
    "                                           lambda u, v: u,\n",
    "                                           lambda u1,u2: u1)\n",
    "test_res_label.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1160', 48), (u'485', 16), (u'1114', 26)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass test picture cluster to restaurant\n",
    "test_res_cluster = test_photo_res_label.map(lambda x: (x[0],x[1])).leftOuterJoin(test_image_cluster).map(lambda x: x[1])\n",
    "test_res_cluster.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine clusters by restaurant and \n",
    "# calculate ratio of each picture cluster under each restaurant as features\n",
    "test_agg_res_cluster = test_res_cluster.combineByKey(lambda x: [x],\n",
    "                                           lambda u, v: u+[v],\n",
    "                                           lambda u1,u2: u1+u2)\\\n",
    "                                .mapValues(lambda x: Counter(x))\\\n",
    "                                .map(lambda x: (x[0], {int(k):float(v)/np.sum(x[1].values()) for k,v in x[1].iteritems()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge test cluster ratio feature and labels\n",
    "test_res_cluster_label = test_agg_res_cluster.leftOuterJoin(test_res_label).map(lambda x: (x[0],x[1][0],x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.777777777778 0.666666666667\n",
      "1 0.828282828283 0.841121495327\n",
      "2 0.79797979798 0.818181818182\n",
      "3 0.676767676768 0.589743589744\n",
      "4 0.868686868687 0.793650793651\n",
      "5 0.79797979798 0.857142857143\n",
      "6 0.787878787879 0.857142857143\n",
      "7 0.79797979798 0.72972972973\n",
      "8 0.838383838384 0.859649122807\n"
     ]
    }
   ],
   "source": [
    "# train logistic regression based on percentage of cluster under each restaurant\n",
    "# make prediction on test set and show f1 score\n",
    "prediction = pd.DataFrame(test_res_cluster_label.map(lambda x: x[0]).collect(),columns=['restaurant_id'])\n",
    "for i in range(9):\n",
    "    train = res_cluster_label.map(lambda x: LabeledPoint(int(x[2][i]), SparseVector(50, x[1]))).cache()\n",
    "    test = test_res_cluster_label.map(lambda x: LabeledPoint(int(x[2][i]), SparseVector(50, x[1]))).cache()\n",
    "    lrm = LogisticRegressionWithLBFGS.train(train, intercept=True, validateData=False)\n",
    "\n",
    "    labelsAndPreds = zip(*test.map(lambda p: (lrm.predict(p.features), p.label)).collect())\n",
    "\n",
    "    current_f1 = f1_score(y_true=labelsAndPreds[1], y_pred=labelsAndPreds[0])\n",
    "    current_accuracy = accuracy_score(y_true=labelsAndPreds[1], y_pred=labelsAndPreds[0])\n",
    "    prediction[('label_%d' % i)]=pd.Series(labelsAndPreds[0])\n",
    "    \n",
    "#     # if predict probability instead of labels\n",
    "#     lrm.clearThreshold()\n",
    "#     labelsAndProbs = zip(*test.map(lambda p: (lrm.predict(p.features), p.label)).collect())\n",
    "#     current_auc = roc_auc_score(y_true=labelsAndProbs[1], y_score=labelsAndProbs[0])\n",
    "    \n",
    "    print i, current_accuracy, current_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined f1 score for all labels\n",
    "def mlb_f1(y_true, y_pred):\n",
    "    y_true = set(y_true)\n",
    "    y_pred = set(y_pred)\n",
    "    tp = len(y_true & y_pred)\n",
    "    fp = len(y_pred-y_true)\n",
    "    fn = len(y_true-y_pred)\n",
    "    p = float(tp)/(tp+fp)\n",
    "    r = float(tp)/(tp+fn)\n",
    "    return 2*p*r/(p+r) if tp!=0 else 0.\n",
    "\n",
    "def mean_f1(y_true, y_pred):\n",
    "    score_list = map(lambda x: mlb_f1(x[0],x[1]), zip(y_true, y_pred))\n",
    "    return sum(score_list)/len(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = [[i for i in range(len(arr)) if arr[i]!=0] for arr in np.array(prediction.iloc[:,1:])]\n",
    "y_true_array = np.array(test_res_cluster_label.map(lambda x: x[2]).collect()).astype(int)\n",
    "y_true = [[i for i in range(len(arr)) if arr[i]!=0] for arr in y_true_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7235923448044658"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall f1 score\n",
    "mean_f1(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show w/ and w/o label ratio in test set\n",
    "test_labels_array = np.array(test_res_cluster_label.map(lambda x: x[2]).collect())\n",
    "test_labels_count = [Counter(arr) for arr in test_labels_array.T]\n",
    "test_labels_freq = [{k:float(v)/np.sum(dict_.values()) for k,v in dict_.iteritems()} for dict_ in test_labels_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'0': 0.6363636363636364, u'1': 0.36363636363636365},\n",
       " {u'0': 0.43434343434343436, u'1': 0.5656565656565656},\n",
       " {u'0': 0.45454545454545453, u'1': 0.5454545454545454},\n",
       " {u'0': 0.5151515151515151, u'1': 0.48484848484848486},\n",
       " {u'0': 0.6868686868686869, u'1': 0.31313131313131315},\n",
       " {u'0': 0.32323232323232326, u'1': 0.6767676767676768},\n",
       " {u'0': 0.25252525252525254, u'1': 0.7474747474747475},\n",
       " {u'0': 0.6161616161616161, u'1': 0.3838383838383838},\n",
       " {u'0': 0.42424242424242425, u'1': 0.5757575757575758}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_freq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
