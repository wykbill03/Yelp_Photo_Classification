{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import lmdb\n",
    "import glob\n",
    "import skimage\n",
    "from skimage import io\n",
    "import numpy\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from caffe import layers as L\n",
    "from caffe import params as P\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from caffe import layers as L\n",
    "# from caffe import params as P\n",
    "\n",
    "def foodCNN(lmdb, batch_size):\n",
    "    # our version of LeNet: a series of linear and simple nonlinear transformations\n",
    "    n = caffe.NetSpec()\n",
    "    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,\n",
    "                             transform_param=dict(scale=1./255), ntop=2)\n",
    "    n.conv1 = L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type='xavier'))\n",
    "    n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.conv2 = L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))\n",
    "    n.pool2 = L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "#     n.ip1 = L.InnerProduct(n.pool2, num_output=500, weight_filler=dict(type='xavier'))\n",
    "    n.conv3 = L.Convolution(n.pool2, kernel_size=5, num_output=50, weight_filler=dict(type='xavier'))\n",
    "    n.pool3 = L.Pooling(n.conv3, kernel_size=2, stride=2, pool=P.Pooling.MAX)\n",
    "    n.ip1 = L.InnerProduct(n.pool3, num_output=500, weight_filler=dict(type='xavier'))\n",
    "    n.relu1 = L.ReLU(n.ip1)\n",
    "    n.ip2 = L.InnerProduct(n.relu1, num_output=2, weight_filler=dict(type='xavier'))\n",
    "    n.loss =  L.SoftmaxWithLoss(n.ip2, n.label)\n",
    "    n.prob = L.Softmax(n.ip2)\n",
    "\n",
    "    return n.to_proto()\n",
    "\n",
    "#     n = caffe.NetSpec()\n",
    "#     n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,\n",
    "#                              transform_param=dict(scale=1./255), ntop=2)\n",
    "#     n.conv1 = L.Convolution(n.data, kernel_size=11, num_output=96, stride=4, \n",
    "#                             weight_filler=dict(type='gaussian', std=0.01),\n",
    "#                             bias_filler=dict(type='constant', value=0),\n",
    "#                             param=learned_param)\n",
    "#     n.relu1 = L.Relu(n.conv1)                         \n",
    "#     n.pool1 = L.Pooling(n.relu1, kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "#     n.norm1 = L.LRN(n.pool1, local_size=5, alpha=0.001, beta=0.75, knorm = 1)\n",
    "#     n.conv2 = L.Convolution(n.norm1, kernel_size=5, num_output=256, pad=2, group=2,\n",
    "#                             weight_filler=dict(type='gaussian', std=0.01), \n",
    "#                             bias_filler=dict(type='constant', value=1))\n",
    "#     n.relu2 = L.Relu(n.conv2)\n",
    "#     n.pool2 = L.Pooling(n.relu2, kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "#     n.norm2 = L.LRN(n.pool2, local_size=5, alpha=0.001, beta=0.75, knorm =1)       \n",
    "#     n.conv3 = L.Convolution(n.norm2, kernel_size=3, num_output=384, pad=1,\n",
    "#                             weight_filler=dict(type='gaussian', std=0.01),\n",
    "#                             bias_filler=dict(type='constant', value=0)) \n",
    "#     n.relu3 = L.Relu(n.conv3)\n",
    "#     n.conv4 = L.Convolution(n.relu3, kernel_size=3, num_output=384, pad=1, group=2,\n",
    "#                             weight_filler=dict(type='gaussian', std=0.01),\n",
    "#                             bias_filler=dict(type='constant', value=1)) \n",
    "#     n.relu4 = L.Relu(n.conv4)\n",
    "#     n.conv5 = L.Convolution(n.relu4, kernel_size=3, num_output=256, pad=1, \n",
    "#                             weight_filler=dict(type='gaussian', std=0.01),\n",
    "#                             bias_filler=dict(type='constant', value=1))\n",
    "#     n.relu5 = L.Relu(n.conv5)\n",
    "#     n.pool5 = L.Pooling(n.conv5, kernel_size=3, stride=2, pool=P.Pooling.MAX)\n",
    "#     n.fc6 = L.InnerProduct(n.pool5, num_output=4096, \n",
    "#                            weight_filler=dict(type='gaussian', std=0.01),\n",
    "#                            bias_filler=dict(type='constant', value=1))\n",
    "#     n.relu6 = L.Relu(n.fc6)\n",
    "#     n.drop1 = L.Dropout(n.relu6, in_place=True)\n",
    "#     n.ip1 = L.InnerProduct(n.drop1, num_output=4096, weight_filler=dict(type='xavier'))\n",
    "#     n.relu1 = L.ReLU(n.ip1, in_place=True)\n",
    "#     n.ip2 = L.InnerProduct(n.relu1, num_output=2, weight_filler=dict(type='xavier'))\n",
    "#     n.loss =  L.SoftmaxWithLoss(n.ip2, n.label)\n",
    "#     n.prob = L.Softmax(n.ip2)\n",
    "#     return n.to_proto()\n",
    "    \n",
    "with open('/home/ubuntu/caffe/yelp/yelp_train.prototxt', 'w') as f:\n",
    "    f.write(str(foodCNN('/home/ubuntu/caffe/yelp/trainnew_lmdb', 64)))\n",
    "    \n",
    "with open('/home/ubuntu/caffe/yelp/yelp_test.prototxt', 'w') as f:\n",
    "    f.write(str(foodCNN('/home/ubuntu/caffe/yelp/testnew_lmdb', 100)))\n",
    "    \n",
    "# run till here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = caffe.SGDSolver('/home/ubuntu/caffe/yelp/yelp_solver.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 training...\n",
      "Iteration 50 training...\n",
      "Iteration 100 training...\n",
      "Iteration 150 training...\n",
      "Iteration 200 training...\n",
      "Iteration 250 training...\n",
      "Iteration 300 training...\n",
      "Iteration 350 training...\n",
      "Iteration 400 training...\n",
      "Iteration 450 training...\n",
      "Iteration 500 training...\n",
      "Iteration 550 training...\n",
      "Iteration 600 training...\n",
      "Iteration 650 training...\n",
      "Iteration 700 training...\n",
      "Iteration 750 training...\n",
      "Iteration 800 training...\n",
      "Iteration 850 training...\n",
      "Iteration 900 training...\n",
      "Iteration 950 training...\n",
      "CPU times: user 1min 11s, sys: 37.5 s, total: 1min 48s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training process\n",
    "niter = 964\n",
    "for it in range(niter):\n",
    "    solver.step(1)\n",
    "    if it % 50 == 0:\n",
    "        print 'Iteration', it, 'training...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 testing...\n",
      "Iteration 50 testing...\n",
      "Iteration 100 testing...\n",
      "Iteration 150 testing...\n",
      "CPU times: user 5.78 s, sys: 2.43 s, total: 8.21 s\n",
      "Wall time: 6.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# testing process\n",
    "correct = 0\n",
    "correct_1 = 0\n",
    "classify_1 = 0\n",
    "num_1 = 0\n",
    "prob_result = np.empty([1])\n",
    "for test_it in range(151):\n",
    "    if test_it % 50 == 0:\n",
    "        print 'Iteration', test_it, 'testing...'\n",
    "    test_out = solver.test_nets[0].forward()\n",
    "    prob_result = np.concatenate((prob_result, test_out['prob'][:,1]), axis=0)\n",
    "    correct += sum(test_out['prob'].argmax(1)\n",
    "                   == solver.test_nets[0].blobs['label'].data)\n",
    "    correct_1 += sum(np.logical_and(test_out['prob'].argmax(1)== solver.test_nets[0].blobs['label'].data, \n",
    "                     solver.test_nets[0].blobs['label'].data == np.ones(100)))\n",
    "    classify_1 += sum(test_out['prob'].argmax(1) == np.ones(100))\n",
    "    num_1 += sum(solver.test_nets[0].blobs['label'].data == np.ones(100, dtype=np.int))\n",
    "\n",
    "test_acc = correct / 15100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.90595668e-310   2.03802183e-001   2.07206458e-001   2.16969937e-001\n",
      "   1.96065068e-001   2.10796133e-001   2.04499796e-001   2.04414278e-001\n",
      "   1.71837896e-001   2.08799288e-001   2.01598182e-001   2.20639125e-001\n",
      "   2.21360967e-001   1.93313226e-001   2.00472608e-001   1.89588770e-001\n",
      "   2.05215842e-001   2.07483336e-001   2.11876646e-001   2.12017566e-001]\n"
     ]
    }
   ],
   "source": [
    "print prob_result[:20]\n",
    "# print test_out['prob'][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_1: 0\n",
      "classify_1: 0\n",
      "num_1: 3270\n"
     ]
    }
   ],
   "source": [
    "print \"correct_1: \" + str(correct_1)\n",
    "print \"classify_1: \" + str(classify_1)\n",
    "print \"num_1: \" + str(num_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall1.0\n",
      "precision0.791059602649\n",
      "f1_score0.883342577186\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "recall = float(correct_1)/num_1\n",
    "precision = float(correct_1)/classify_1\n",
    "f1_score = 2*precision*recall/(precision + recall)\n",
    "print \"recall\" + str(recall)\n",
    "print \"precision\" + str(precision)\n",
    "print \"f1_score\" +  str(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ubuntu/caffe/yelp/pic_label_subbybus_test.csv', sep=',')\n",
    "df_sub = df.iloc[:len(prob_result),[0,1,3]]\n",
    "df_prob = pd.DataFrame({'prob':prob_result})\n",
    "frames = [df_sub, df_prob]\n",
    "df_result = pd.concat(frames, axis=1)\n",
    "print df_result.ix[:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write the result into file\n",
    "df_result.to_csv('/home/ubuntu/caffe/yelp/prob_result/prob_result0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-edf9e11f2308>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwinx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_interval\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADcpJREFUeJzt3F+oXWeZx/Hvr2Y6MFILtVAwtWWmWopiFdFMLnqxbWWa\nehPxxrZQsSAEZireGb2QngvB8U6cohIIiheSATswGUfHinQjnWk1Qv/omJhWh9ikUqn/QKEQwzMX\nZ/fJzvbk7HWSvfeJ6fcDC/Za+z3v+56XvZ9f1lpnJVWFJEkAV2z3BCRJlw5DQZLUDAVJUjMUJEnN\nUJAkNUNBktTmhkKSg0leTPLMJm0+n+TZJE8lecdipyhJmrWs2jzkTOHLwJ2bDHoXcFNVvRnYB3xp\nyMCSpIuylNo8NxSq6jHgt5s02Qt8ddL2+8DVSa4bMrgk6cIsqzYv4p7CTuD5qf1Tk2OSpO1zQbXZ\nG82SpLZjAX2cAt44tX/95NifSeJ/tCRJF6CqssUfGVybpw09U8hk28hh4EMASXYDv6uqF8/XUVW5\nVfHggw9u+xwulc21cC1ci823VdTmV8w9U0jyNWAEvD7JL4AHgSvX63sdqKpvJnlfkueAPwL3z+tT\nknRxllWb54ZCVd07oM0DQwaTJC3GsmqzN5q3yWg02u4pXDJci7Nci7Nci+2ROderFjtYUqscT5Iu\nB0mord9oviCeKUiSmqEgSWqGgiSpGQqSpGYoSJKaoSBJaoaCJKkZCpKkZihIkpqhIElqhoIkqRkK\nkqRmKEiSmqEgSWqGgiSpGQqSpGYoSJKaoSBJaoaCJKkZCpKkZihIkpqhIElqhoIkqRkKkqRmKEiS\nmqEgSWqGgiSpGQqSpGYoSJKaoSBJaoaCJKkZCpKkZihIkpqhIElqg0IhyZ4kx5IcT7J/g/dfl+Rw\nkqeS/CjJhxc+U0nSOZZRm1NV8wa9AjgO3AG8ABwB7q6qY1NtPgm8rqo+meRa4KfAdVX1p5m+at54\nkqRzJaGqMnNsYbV52pAzhV3As1V1oqpOA4eAvTNtCrhq8voq4NebDSpJumhLqc1DQmEn8PzU/snJ\nsWkPAW9J8gLwNPCxAf1Kki7cUmrzjgVN7k7gyaq6PclNwHeS3FpVf5htuLa21q9HoxGj0WhBU5Ck\ny8N4PGY8Hi+iq8G1+RVD7insBtaqas9k/xNAVdVnp9p8A/hMVf33ZP+7wP6q+uFMX95TkKQtOs89\nhYXV5mlDLh8dAd6U5MYkVwJ3A4dn2pwA3jsZ9DrgZuDnA/qWJF2YpdTmuZePqupMkgeAR1gPkYNV\ndTTJvvW36wDwaeArSZ6Z/NjHq+o3w383SdJWLKs2z718tEhePpKkrdvo8tGy+ESzJKkZCpKkZihI\nkpqhIElqhoIkqRkKkqRmKEiSmqEgSWqGgiSpGQqSpGYoSJKaoSBJaoaCJKkZCpKkZihIkpqhIElq\nhoIkqRkKkqRmKEiSmqEgSWqGgiSpGQqSpGYoSJKaoSBJaoaCJKkZCpKkZihIkpqhIElqhoIkqRkK\nkqRmKEiSmqEgSWqGgiSpGQqSpGYoSJLaoFBIsifJsSTHk+w/T5tRkieT/DjJo4udpiRp1jJqc6pq\n3qBXAMeBO4AXgCPA3VV1bKrN1cD/AP9QVaeSXFtVL23QV80bT5J0riRUVWaOLaw2TxtyprALeLaq\nTlTVaeAQsHemzb3Aw1V1CmDeoJKki7aU2jwkFHYCz0/tn5wcm3YzcE2SR5McSXLfgH4lSRduKbV5\nx4ImtwN4J3A78Frg8SSPV9VzC+pfkrR1W67NQ0LhFHDD1P71k2PTTgIvVdXLwMtJvge8HfizgdfW\n1vr1aDRiNBoNmIIkvXqMx2PG4/G8Zgutza8YcqP5NcBPWb+Z8UvgB8A9VXV0qs0twL8Ae4C/Br4P\nfLCqfjLTlzeaJWmLznOjeWG1edrcM4WqOpPkAeAR1u9BHKyqo0n2rb9dB6rqWJJvA88AZ4ADmw0q\nSbo4y6rNc88UFskzBUnauo3OFJbFJ5olSc1QkCQ1Q0GS1AwFSVIzFCRJzVCQJDVDQZLUDAVJUjMU\nJEnNUJAkNUNBktQMBUlSMxQkSc1QkCQ1Q0GS1AwFSVIzFCRJzVCQJDVDQZLUDAVJUjMUJEnNUJAk\nNUNBktQMBUlSMxQkSc1QkCQ1Q0GS1AwFSVIzFCRJzVCQJDVDQZLUDAVJUjMUJEnNUJAkNUNBktQM\nBUlSGxQKSfYkOZbkeJL9m7R7d5LTST6wuClKkjayjNo8NxSSXAE8BNwJvBW4J8kt52n3z8C35/Up\nSbo4y6rNQ84UdgHPVtWJqjoNHAL2btDuo8DXgV8NGViSdFGWUpuHhMJO4Pmp/ZOTYy3JG4D3V9UX\ngQwZWJJ0UZZSmxd1o/lzwPT1LINBkrbflmvzjgGdngJumNq/fnJs2ruAQ0kCXAvcleR0VR2e7Wxt\nba1fj0YjRqPRgClI0qvHeDxmPB7Pa7bQ2vyKVNWmoyZ5DfBT4A7gl8APgHuq6uh52n8Z+I+q+rcN\n3qt540mSzpWEqsrMsYXV5mlzzxSq6kySB4BHWL/cdLCqjibZt/52HZj9kXl9SpIuzrJq89wzhUXy\nTEGStm6jM4Vl8YlmSVIzFCRJzVCQJDVDQZLUDAVJUjMUJEnNUJAkNUNBktQMBUlSMxQkSc1QkCQ1\nQ0GS1AwFSVIzFCRJzVCQJDVDQZLUDAVJUjMUJEnNUJAkNUNBktQMBUlSMxQkSc1QkCQ1Q0GS1AwF\nSVIzFCRJzVCQJDVDQZLUDAVJUjMUJEnNUJAkNUNBktQMBUlSMxQkSc1QkCQ1Q0GS1AaFQpI9SY4l\nOZ5k/wbv35vk6cn2WJK3LX6qkqRpy6jNqap5g14BHAfuAF4AjgB3V9WxqTa7gaNV9fske4C1qtq9\nQV81bzxJ0rmSUFWZObaw2jxtyJnCLuDZqjpRVaeBQ8De6QZV9URV/X6y+wSwc0C/kqQLt5TaPCQU\ndgLPT+2fnNPxR4BvDehXknThllKbd1zkpM6R5D3A/cBt52uztrbWr0ejEaPRaJFTkKS/eOPxmPF4\nvLD+htTmbjvgnsJu1q9D7ZnsfwKoqvrsTLtbgYeBPVX1s/P05T0FSdqi89xTWFhtnjbk8tER4E1J\nbkxyJXA3cHhm0Bsmg943ZFBJ0kVbSm2ee/moqs4keQB4hPUQOVhVR5PsW3+7DgCfAq4BvpAkwOmq\n2rWFX06StAXLqs1zLx8tkpePJGnrNrp8tCw+0SxJaoaCJKkZCpKkZihIkpqhIElqhoIkqRkKkqRm\nKEiSmqEgSWqGgiSpGQqSpGYoSJKaoSBJaoaCJKkZCpKkZihIkpqhIElqhoIkqRkKkqRmKEiSmqEg\nSWqGgiSpGQqSpGYoSJKaoSBJaoaCJKkZCpKkZihIkpqhIElqhoIkqRkKkqRmKEiSmqEgSWqGgiSp\nGQqSpDYoFJLsSXIsyfEk+8/T5vNJnk3yVJJ3LHaakqRZy6jNc0MhyRXAQ8CdwFuBe5LcMtPmLuCm\nqnozsA/40oDf51VtPB5v9xQuGa7FWa7FWa7F5pZVm4ecKewCnq2qE1V1GjgE7J1psxf4KkBVfR+4\nOsl1A/p+1fIDf5ZrcZZrcZZrMddSavOQUNgJPD+1f3JybLM2pzZoI0lanKXUZm80S5LOqqpNN2A3\n8F9T+58A9s+0+RLwwan9Y8B1G/RVbm5ubm5b35ZZm6e3Hcx3BHhTkhuBXwJ3A/fMtDkM/BPwr0l2\nA7+rqhdnO6qqDBhPkjTfwmrztLmhUFVnkjwAPML65aaDVXU0yb71t+tAVX0zyfuSPAf8Ebh/q7+d\nJGm4ZdXmTE4pJElazo1mH3Y7a95aJLk3ydOT7bEkb9uOea7CkM/FpN27k5xO8oFVzm+VBn5HRkme\nTPLjJI+ueo6rMuA78rokhye14kdJPrwN01y6JAeTvJjkmU3aLL9uzrvRvNWN9aB5DrgR+CvgKeCW\nmTZ3Af85ef33wBOLnselsA1ci93A1ZPXe17NazHV7rvAN4APbPe8t/FzcTXwv8DOyf612z3vbVyL\nTwKfeWUdgF8DO7Z77ktYi9uAdwDPnOf9ldTNZZwp+LDbWXPXoqqeqKrfT3af4PJ9vmPI5wLgo8DX\ngV+tcnIrNmQt7gUerqpTAFX10ornuCpD1qKAqyavrwJ+XVV/WuEcV6KqHgN+u0mTldTNZYSCD7ud\nNWQtpn0E+NZSZ7R95q5FkjcA76+qLwKX81+qDflc3Axck+TRJEeS3Ley2a3WkLV4CHhLkheAp4GP\nrWhul5qV1M0hf5KqFUjyHtb/MuC27Z7LNvocMH1N+XIOhnl2AO8EbgdeCzye5PGqem57p7Ut7gSe\nrKrbk9wEfCfJrVX1h+2e2OVoGaFwCrhhav/6ybHZNm+c0+ZyMGQtSHIrcADYU1WbnT7+JRuyFu8C\nDiUJ69eO70pyuqoOr2iOqzJkLU4CL1XVy8DLSb4HvJ316++XkyFrcT/wGYCq+lmS/wNuAX64khle\nOlZSN5dx+agfqEhyJesPVMx+qQ8DHwIY+kDFX6i5a5HkBuBh4L6q+tk2zHFV5q5FVf3dZPtb1u8r\n/ONlGAgw7Dvy78BtSV6T5G9Yv7F4dMXzXIUha3ECeC/A5Br6zcDPVzrL1QnnP0NeSd1c+JlC+bBb\nG7IWwKeAa4AvTP6FfLqqdm3frJdj4Fqc8yMrn+SKDPyOHEvybeAZ4AxwoKp+so3TXoqBn4tPA1+Z\n+lPNj1fVb7ZpykuT5GvACHh9kl8ADwJXsuK66cNrkqTm/5IqSWqGgiSpGQqSpGYoSJKaoSBJaoaC\nJKkZCpKkZihIktr/AwQRRY78m+1LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8835b68f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy plot\n",
    "_, ax1 = subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(arange(niter), train_loss)\n",
    "ax2.plot(test_interval * arange(len(test_acc)), test_acc, 'r')\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('train loss')\n",
    "ax2.set_ylabel('test accuracy')\n",
    "ax2.set_title('Test Accuracy: {:.2f}'.format(test_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 testing...\n",
      "[[ 0.23812878  0.76187122]]\n",
      "[[ 0.25141978  0.74858022]]\n",
      "[[ 0.24623427  0.75376576]]\n",
      "[[ 0.2499115   0.75008851]]\n",
      "[[ 0.22863993  0.7713601 ]]\n",
      "[[ 0.23540573  0.76459432]]\n",
      "[[ 0.2544457   0.74555433]]\n",
      "[[ 0.24187724  0.75812268]]\n",
      "[[ 0.24191846  0.75808156]]\n",
      "[[ 0.24375363  0.75624633]]\n",
      "[[ 0.23577744  0.76422256]]\n",
      "[[ 0.24305959  0.75694042]]\n",
      "[[ 0.24541208  0.75458789]]\n",
      "[[ 0.23726609  0.76273394]]\n",
      "[[ 0.24246319  0.75753683]]\n",
      "[[ 0.25106889  0.74893111]]\n",
      "[[ 0.22808327  0.77191669]]\n",
      "[[ 0.24100056  0.75899947]]\n",
      "[[ 0.23111324  0.76888674]]\n",
      "[[ 0.23520339  0.76479667]]\n",
      "[[ 0.23556991  0.76443011]]\n",
      "[[ 0.23721808  0.76278192]]\n",
      "[[ 0.242328    0.75767201]]\n",
      "[[ 0.23791555  0.76208442]]\n",
      "[[ 0.24965565  0.75034434]]\n",
      "[[ 0.25270754  0.74729252]]\n",
      "[[ 0.23778945  0.76221055]]\n",
      "[[ 0.25396895  0.74603105]]\n",
      "[[ 0.24877101  0.75122905]]\n",
      "[[ 0.24190906  0.75809091]]\n",
      "[[ 0.23820223  0.76179779]]\n",
      "[[ 0.25379553  0.74620444]]\n",
      "[[ 0.25500569  0.74499428]]\n",
      "[[ 0.2442234   0.75577664]]\n",
      "[[ 0.25328976  0.74671018]]\n",
      "[[ 0.23157309  0.76842695]]\n",
      "[[ 0.23297764  0.76702231]]\n",
      "[[ 0.23090477  0.76909524]]\n",
      "[[ 0.23620804  0.76379198]]\n",
      "[[ 0.23059905  0.76940095]]\n",
      "[[ 0.23487301  0.76512706]]\n",
      "[[ 0.24855387  0.75144613]]\n",
      "[[ 0.23973885  0.76026112]]\n",
      "[[ 0.24031614  0.75968391]]\n",
      "[[ 0.23970072  0.76029921]]\n",
      "[[ 0.22557138  0.77442867]]\n",
      "[[ 0.23985153  0.76014847]]\n",
      "[[ 0.22766218  0.77233779]]\n",
      "[[ 0.23926978  0.76073021]]\n",
      "[[ 0.25622815  0.74377185]]\n",
      "[[ 0.23930065  0.76069933]]\n",
      "[[ 0.23713546  0.76286453]]\n",
      "[[ 0.2502012   0.74979877]]\n",
      "[[ 0.2292259   0.77077407]]\n",
      "[[ 0.23994191  0.76005805]]\n",
      "[[ 0.25232098  0.74767905]]\n",
      "[[ 0.23410936  0.76589066]]\n",
      "[[ 0.24470025  0.75529975]]\n",
      "[[ 0.24949346  0.75050652]]\n",
      "[[ 0.25176173  0.74823827]]\n",
      "[[ 0.22707422  0.77292573]]\n",
      "[[ 0.24122009  0.75877994]]\n",
      "[[ 0.25466114  0.7453388 ]]\n",
      "[[ 0.23285042  0.76714957]]\n",
      "[[ 0.2407959   0.75920409]]\n",
      "[[ 0.23745784  0.76254213]]\n",
      "[[ 0.23877563  0.76122439]]\n",
      "[[ 0.24729276  0.75270718]]\n",
      "[[ 0.25093988  0.74906009]]\n",
      "[[ 0.22483577  0.77516425]]\n",
      "[[ 0.24598852  0.75401151]]\n",
      "[[ 0.23073941  0.76926059]]\n",
      "[[ 0.23013254  0.76986742]]\n",
      "[[ 0.23831594  0.76168406]]\n",
      "[[ 0.25426739  0.74573261]]\n",
      "[[ 0.22878878  0.77121121]]\n",
      "[[ 0.2380901  0.7619099]]\n",
      "[[ 0.2392301  0.7607699]]\n",
      "[[ 0.24126369  0.75873625]]\n",
      "[[ 0.24101761  0.75898236]]\n",
      "[[ 0.23347543  0.76652455]]\n",
      "[[ 0.23788434  0.7621156 ]]\n",
      "[[ 0.25307071  0.74692935]]\n",
      "[[ 0.24027003  0.75972998]]\n",
      "[[ 0.23299281  0.76700717]]\n",
      "[[ 0.23262557  0.7673744 ]]\n",
      "[[ 0.24035026  0.75964975]]\n",
      "[[ 0.23672695  0.76327306]]\n",
      "[[ 0.23459868  0.7654013 ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-99ffde47ff66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu\"niter = 964\\ntest_interval = 50\\n# losses will also be stored in the log\\ntrain_loss = zeros(niter)\\ntest_acc = zeros(int(np.ceil(niter / test_interval)))\\n# output = zeros((niter, 8, 2))\\n\\n# the main solver loop\\nfor it in range(niter):\\n#     solver.net.forward()\\n    solver.step(1)\\n    # store the train loss\\n    train_loss[it] = solver.net.blobs['loss'].data\\n    \\n    # store the output on the first test batch\\n    # (start the forward pass at conv1 to avoid loading new data)\\n#     solver.test_nets[0].forward(start='conv1')\\n#     output[it] = solver.test_nets[0].blobs['ip2'].data[:8]\\n    \\n    if it % test_interval == 0:\\n        print 'Iteration', it, 'testing...'\\n        correct = 0\\n        correct_1 = 0\\n        classify_1 = 0\\n        num_1 = 0\\n        for test_it in range(151):\\n            test_out = solver.test_nets[0].forward()\\n            print test_out['prob'][:1]\\n            correct += sum(test_out['prob'].argmax(1)\\n                           == solver.test_nets[0].blobs['label'].data)\\n            correct_1 += sum(np.logical_and(test_out['prob'].argmax(1)== solver.test_nets[0].blobs['label'].data, \\n                             solver.test_nets[0].blobs['label'].data == np.ones(100)))\\n            classify_1 += sum(test_out['prob'].argmax(1) == np.ones(100))\\n            num_1 += sum(solver.test_nets[0].blobs['label'].data == np.ones(100, dtype=np.int))\\n            \\n        test_acc[it // test_interval] = correct / 15100.0\\n        correct_1 = correct_1\\n        num_1 = num_1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/caffe/python/caffe/pycaffe.pyc\u001b[0m in \u001b[0;36m_Net_forward\u001b[1;34m(self, blobs, start, end, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0min_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;31m# Unpack blobs to extract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "niter = 964\n",
    "test_interval = 50\n",
    "# losses will also be stored in the log\n",
    "train_loss = zeros(niter)\n",
    "test_acc = zeros(int(np.ceil(niter / test_interval)))\n",
    "# output = zeros((niter, 8, 2))\n",
    "\n",
    "# the main solver loop\n",
    "for it in range(niter):\n",
    "#     solver.net.forward()\n",
    "    solver.step(1)\n",
    "    # store the train loss\n",
    "    train_loss[it] = solver.net.blobs['loss'].data\n",
    "    \n",
    "    # store the output on the first test batch\n",
    "    # (start the forward pass at conv1 to avoid loading new data)\n",
    "#     solver.test_nets[0].forward(start='conv1')\n",
    "#     output[it] = solver.test_nets[0].blobs['ip2'].data[:8]\n",
    "    \n",
    "    if it % test_interval == 0:\n",
    "        print 'Iteration', it, 'testing...'\n",
    "        correct = 0\n",
    "        correct_1 = 0\n",
    "        classify_1 = 0\n",
    "        num_1 = 0\n",
    "        for test_it in range(151):\n",
    "            test_out = solver.test_nets[0].forward()\n",
    "            print test_out['prob'][:1]\n",
    "            correct += sum(test_out['prob'].argmax(1)\n",
    "                           == solver.test_nets[0].blobs['label'].data)\n",
    "            correct_1 += sum(np.logical_and(test_out['prob'].argmax(1)== solver.test_nets[0].blobs['label'].data, \n",
    "                             solver.test_nets[0].blobs['label'].data == np.ones(100)))\n",
    "            classify_1 += sum(test_out['prob'].argmax(1) == np.ones(100))\n",
    "            num_1 += sum(solver.test_nets[0].blobs['label'].data == np.ones(100, dtype=np.int))\n",
    "            \n",
    "        test_acc[it // test_interval] = correct / 15100.0\n",
    "        correct_1 = correct_1\n",
    "        num_1 = num_1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
